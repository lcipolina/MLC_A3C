{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a3c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moodlep/MLC_A3C/blob/main/a3c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oq0AxEo1W9o",
        "outputId": "38acea0f-628c-4259-b8f3-c97cde67e20d"
      },
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deq0in1i1iM7"
      },
      "source": [
        "import os\n",
        "import Box2D\n",
        "import pyglet\n",
        "import imageio\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "954_wRxQtHoe"
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjrzTEmz1Q3L",
        "outputId": "21efd509-bec3-46b6-fc9b-cecbf24acd7d"
      },
      "source": [
        "# The env - quick test: \n",
        "\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "s = env.reset()\n",
        "\n",
        "for _ in range(5): \n",
        "  a = env.action_space.sample()\n",
        "  next_state, reward, done, info = env.step(a)\n",
        "  print(next_state, reward, a)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.01579113  1.4081995   0.79524124 -0.04177593 -0.01859165 -0.18812022\n",
            "  0.          0.        ] -0.038094736960334774 2\n",
            "[ 0.02357159  1.4066625   0.7855884  -0.06842816 -0.02604947 -0.14916997\n",
            "  0.          0.        ] 0.14451482824213827 1\n",
            "[ 0.03129129  1.4053156   0.7798752  -0.06002046 -0.03386489 -0.15632293\n",
            "  0.          0.        ] -0.3237968686503507 2\n",
            "[ 0.03917313  1.4044763   0.7954258  -0.03748155 -0.04102248 -0.1431656\n",
            "  0.          0.        ] -2.3643076220101475 2\n",
            "[ 0.04715729  1.4042549   0.80530965 -0.01004783 -0.04785093 -0.13658157\n",
            "  0.          0.        ] -1.8916400234749233 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVEU5PUOG7aU"
      },
      "source": [
        "class SharedAdam(torch.optim.Adam):\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
        "                 weight_decay=0):\n",
        "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        # State initialization\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                state['step'] = 0\n",
        "                state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                # share in memory\n",
        "                state['exp_avg'].share_memory_()\n",
        "                state['exp_avg_sq'].share_memory_()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7EURhaU18Rl",
        "outputId": "53cf88f8-35bf-49f0-a473-bebc73665ae6"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkudVJbo_q6f"
      },
      "source": [
        "### Actor - policy NN and value NN \n",
        "### data collection -> batch\n",
        "### train: calculate loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTIuEegY2JYl"
      },
      "source": [
        "\n",
        "class Policy(nn.Module):\n",
        "\tdef __init__(self, state_dim,action_dim,hidden=100):\n",
        "\t\tsuper(Policy, self).__init__()\n",
        "\n",
        "\t\tself.l1 = nn.Linear(state_dim, hidden)\n",
        "\t\tself.l2 = nn.Linear(hidden, hidden)\n",
        "\t\tself.l3 = nn.Linear(hidden,action_dim)\n",
        "\n",
        "\tdef forward(self, state):\n",
        "\t\tq = F.leaky_relu(self.l1(state))\n",
        "\t\tq = F.leaky_relu(self.l2(q))\n",
        "\t\treturn F.softmax(self.l3(q), dim = 1)\n",
        "\t\n",
        "\tdef get_action(self,state):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\tdist = torch.distributions.Categorical(pol)\n",
        "\t\treturn dist.sample() #returns a batch of values\n",
        "\t\n",
        "\tdef log_prob(self, state, actions):\n",
        "\t\t  # Part of the loss term\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\tlog_prob = torch.distributions.Categorical(pol).log_prob(actions)\n",
        "\t\t\treturn log_prob\n",
        "\t\n",
        "\tdef entropy(self, state):\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\treturn torch.distributions.Categorical(pol).entropy()\n",
        "    \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en5eOtrYe0dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1638b3-7542-4f1d-cd34-0d1816cb6113"
      },
      "source": [
        "# create batch of states \n",
        "batch_states = torch.rand(5, env.observation_space.shape[0])\n",
        "\n",
        "policy = Policy(env.observation_space.shape[0], env.action_space.n)\n",
        "policy(batch_states).data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2250, 0.2561, 0.2576, 0.2612],\n",
              "        [0.2141, 0.2636, 0.2563, 0.2661],\n",
              "        [0.2091, 0.2661, 0.2586, 0.2662],\n",
              "        [0.2164, 0.2614, 0.2632, 0.2590],\n",
              "        [0.2224, 0.2532, 0.2632, 0.2612]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaOYNnx3hBnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cdeb56-4c0b-4763-af0b-b21d1b808412"
      },
      "source": [
        "batch_actions = policy.get_action(batch_states)\n",
        "batch_actions"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 3, 3, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkd5Oabji-el",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a0fa3d-a0d0-45a6-d60d-5b212fe8ef05"
      },
      "source": [
        "policy.log_prob(batch_states, batch_actions)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.4916, -1.3240, -1.3234, -1.3418, -1.3425],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AYm6eCD53O2"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim,hidden=100):\n",
        "      super(Critic, self).__init__()\n",
        "    \n",
        "      self.l1 = nn.Linear(state_dim, hidden)\n",
        "      self.l2 = nn.Linear(hidden, hidden)\n",
        "      self.l3 = nn.Linear(hidden,1)\n",
        "\n",
        "    def forward(self, state):\n",
        "      q = F.leaky_relu(self.l1(state))\n",
        "      q = F.leaky_relu(self.l2(q))\n",
        "      return self.l3(q)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBBJ9hbfA7Hs"
      },
      "source": [
        "class ActorCritic(mp.Process):\n",
        "\tdef __init__(self,env_name,glb_critic,glb_policy,opt_crt,opt_pol,max_step=100):\n",
        "\t\tself.env = gym.make(env_name)\n",
        "\t\tself.t = 0\n",
        "\t\tself.max_step = max_step\n",
        "\n",
        "\t\tself.actor = Policy(self.env.observation_space.shape[0], self.env.action_space.n)\n",
        "\t\tself.critic = Critic(self.env.observation_space.shape[0])\n",
        "\t\tself.global_critic = global_critic\n",
        "\t\tself.global_policy = global_policy\n",
        "\t\n",
        "\tdef run(self):\n",
        "\n",
        "\t\t# 1. Sync local from global\n",
        "\t\tself.actor.load_state_dict(self.global_policy.state_dict())\n",
        "\t\tself.critic.load_state_dict(self.global_critic.state_dict())\n",
        "\t\n",
        "\t\t# 2. Create a rollout\n",
        "\n",
        "\n",
        "\t\t# 3. \n",
        "\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWowuEK249kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f316f89d-656a-43b0-f115-9a1186254382"
      },
      "source": [
        "# worker process\n",
        "# Input: A2C network, env, no of steps, \n",
        "\n",
        "# 1. \n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "global_critic = Critic(state_dim)\n",
        "global_policy = Policy(state_dim,action_dim)\n",
        "global_critic.share_memory()\n",
        "global_policy.share_memory()\n",
        "\n",
        "global_opt_crt = SharedAdam(global_critic.parameters())\n",
        "global_opt_pol = SharedAdam(global_policy.parameters())\n",
        "\n",
        "\n",
        "global_ctr = mp.Value('i',0)\n",
        "lock = mp.Lock()\n",
        "\n",
        "pr = [mp.Process(target=test,args=(a,)) for _ in range(5)]\n",
        "\n",
        "for p in pr:\n",
        "    p.start()\n",
        "\n",
        "    \n",
        "for p in pr:\n",
        "    p.join()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Policy(\n",
              "  (l1): Linear(in_features=8, out_features=100, bias=True)\n",
              "  (l2): Linear(in_features=100, out_features=100, bias=True)\n",
              "  (l3): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}