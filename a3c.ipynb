{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a3c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moodlep/MLC_A3C/blob/main/a3c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oq0AxEo1W9o",
        "outputId": "1a657195-dd3b-4cee-f3d0-20ee2d00f3fd"
      },
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 448 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deq0in1i1iM7"
      },
      "source": [
        "import os\n",
        "import Box2D\n",
        "import pyglet\n",
        "import imageio\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "954_wRxQtHoe"
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjrzTEmz1Q3L",
        "outputId": "b117d175-dbeb-415e-e517-7d63dc411983"
      },
      "source": [
        "# The env - quick test: \n",
        "\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "s = env.reset()\n",
        "\n",
        "for _ in range(5): \n",
        "  a = env.action_space.sample()\n",
        "  next_state, reward, done, info = env.step(a)\n",
        "  print(next_state, reward, a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00671301  1.3930244  -0.3336074  -0.4105778   0.00580508  0.0372713\n",
            "  0.          0.        ] -0.5840980788976526 3\n",
            "[-0.00994568  1.3831863  -0.3229907  -0.43725243  0.00553722 -0.00535743\n",
            "  0.          0.        ] -0.47987389698741256 3\n",
            "[-0.01317825  1.372748   -0.32298952 -0.46392414  0.00527007 -0.0053438\n",
            "  0.          0.        ] -1.0996906444878505 0\n",
            "[-0.01624842  1.3630856  -0.30755308 -0.4294401   0.00580306  0.01066116\n",
            "  0.          0.        ] 4.3169633396255565 2\n",
            "[-0.01931849  1.3528231  -0.3075549  -0.45611992  0.00633539  0.01064755\n",
            "  0.          0.        ] -1.2222191633063915 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVEU5PUOG7aU"
      },
      "source": [
        "class SharedAdam(torch.optim.Adam):\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
        "                 weight_decay=0):\n",
        "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        # State initialization\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                state['step'] = 0\n",
        "                state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                # share in memory\n",
        "                state['exp_avg'].share_memory_()\n",
        "                state['exp_avg_sq'].share_memory_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7EURhaU18Rl",
        "outputId": "aefd6000-1ff7-4ba1-e958-1262065898c8"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkudVJbo_q6f"
      },
      "source": [
        "### Actor - policy NN and value NN \n",
        "### data collection -> batch\n",
        "### train: calculate loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTIuEegY2JYl"
      },
      "source": [
        "\n",
        "class Policy(nn.Module):\n",
        "\tdef __init__(self, state_dim,action_dim,hidden=100):\n",
        "\t\tsuper(Policy, self).__init__()\n",
        "\n",
        "\t\tself.l1 = nn.Linear(state_dim, hidden)\n",
        "\t\tself.l2 = nn.Linear(hidden, hidden)\n",
        "\t\tself.l3 = nn.Linear(hidden,action_dim)\n",
        "\n",
        "\tdef forward(self, state):\n",
        "\t\tq = F.leaky_relu(self.l1(state))\n",
        "\t\tq = F.leaky_relu(self.l2(q))\n",
        "\t\treturn F.softmax(self.l3(q), dim = 1)\n",
        "\t\n",
        "\tdef get_action(self,state):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\tdist = torch.distributions.Categorical(pol)\n",
        "\t\treturn dist.sample() #returns a batch of values\n",
        "\t\n",
        "\tdef log_prob(self, state, actions):\n",
        "\t\t  # Part of the loss term\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\tlog_prob = torch.distributions.Categorical(pol).log_prob(actions)\n",
        "\t\t\treturn log_prob\n",
        "\t\n",
        "\tdef entropy(self, state):\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\treturn torch.distributions.Categorical(pol).entropy()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en5eOtrYe0dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e63660c-73d1-408f-b823-2aa970eeed75"
      },
      "source": [
        "# create batch of states \n",
        "batch_states = torch.rand(5, env.observation_space.shape[0])\n",
        "\n",
        "policy = Policy(env.observation_space.shape[0], env.action_space.n)\n",
        "policy(batch_states).data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2868, 0.2679, 0.2083, 0.2371],\n",
              "        [0.2706, 0.2647, 0.2139, 0.2509],\n",
              "        [0.2659, 0.2731, 0.2127, 0.2483],\n",
              "        [0.2693, 0.2704, 0.2137, 0.2466],\n",
              "        [0.2707, 0.2673, 0.2149, 0.2472]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaOYNnx3hBnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d45e7b-48d1-4af1-f528-06bf53e4990e"
      },
      "source": [
        "batch_actions = policy.get_action(batch_states)\n",
        "batch_actions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkd5Oabji-el",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233761c1-bc36-4996-85e9-429474bb968e"
      },
      "source": [
        "policy.log_prob(batch_states, batch_actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.3171, -1.3293, -1.5480, -1.5429, -1.3069],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AYm6eCD53O2"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim,hidden=100):\n",
        "      super(Critic, self).__init__()\n",
        "    \n",
        "      self.l1 = nn.Linear(state_dim, hidden)\n",
        "      self.l2 = nn.Linear(hidden, hidden)\n",
        "      self.l3 = nn.Linear(hidden,1)\n",
        "\n",
        "    def forward(self, state):\n",
        "      q = F.leaky_relu(self.l1(state))\n",
        "      q = F.leaky_relu(self.l2(q))\n",
        "      return self.l3(q)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NJlftFuaPxE",
        "outputId": "480670eb-d879-48cd-c058-b7019f3d2804"
      },
      "source": [
        "#testing the critic output\n",
        "critic = Critic(env.observation_space.shape[0])\n",
        "critic(batch_states[0]).shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBBJ9hbfA7Hs"
      },
      "source": [
        "class ActorCriticWorker(mp.Process):\n",
        "\tdef __init__(self,env_name,glb_critic,glb_policy,opt_crt,opt_pol,T,lock,gamma = 0.99,max_step=100):\n",
        "\t\tself.env = gym.make(env_name)\n",
        "\t\tself.t = 0\n",
        "\t\tself.max_step = max_step\n",
        "\t\tself.T = T\n",
        "\t\tself.lock = lock\n",
        "\t\tself.gamma = gamma\n",
        "\n",
        "\t\tself.actor = Policy(self.env.observation_space.shape[0], self.env.action_space.n)\n",
        "\t\tself.critic = Critic(self.env.observation_space.shape[0])\n",
        "\t\tself.global_critic = global_critic\n",
        "\t\tself.global_policy = global_policy\n",
        "\t\n",
        "\tdef run(self):\n",
        "\n",
        "\t\t# 1. Sync local from global\n",
        "\t\tself.actor.load_state_dict(self.global_policy.state_dict())\n",
        "\t\tself.critic.load_state_dict(self.global_critic.state_dict())\n",
        "\t\n",
        "\t\t# 2. Create a rollout\n",
        "\t\tt_start = self.t\t\t\n",
        "\t\tstate   = self.env.reset() #giving us a state from the gym env.\n",
        "\t  done    = False\n",
        "\t\tstates  = []\n",
        "\t\tactions = []\n",
        "\t\trewards = []\n",
        "\t\twhile not done and (self.t - t_start+1)%self.max_step !=0:\n",
        "\t\t\t    action = self.actor.get_action(state)\n",
        "\t\t\t    next_state, reward,done, _info = self.env.step(action)\n",
        "\t\t\t    rewards.append(reward)\n",
        "\t\t\t    actions.append(action)\n",
        "\t\t\t \t\tstates.append(state)\n",
        "\t\t\t    state = next_state\n",
        "\t\t\t\t\tself.t  += 1\t\t\t\t\t\n",
        "\t\t\t\t\t# lock memory\n",
        "\t\t\t\t\twith self.lock:\n",
        "\t\t\t\t\t\tself.T.value +=1\n",
        "\n",
        "\t\t# Calculate reward\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tif not done:\t\t\t\n",
        "\t\t\t\tR = self.critic(torch.tensor(state,dtype = torch.float64)) #calculating the value function\n",
        "\t\t\telse:\n",
        "\t\t\t\tR = torch.tensor([0],dtype = torch.float64)\n",
        "\t\t\n",
        "\t\tfor i in range(len(states)-1,-1,-1):\n",
        "\t\t\t  R = torch.tensor([rewards[i]]) + self.gamma*R\n",
        "\t\t\t\t#Calculating gradients\n",
        "\t\t\t\t\n",
        "\n",
        "\n",
        "\t\t# 3. Calculate loss \n",
        "\n",
        "\n",
        "\n",
        "# T is a global counter\n",
        "# Tmax is total steps overall\n",
        "# t is the local counter per process\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWowuEK249kp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "fa1f0357-65b6-4904-de5b-fbbf44cba5c6"
      },
      "source": [
        "# worker process\n",
        "# Input: A2C network, env, no of steps, \n",
        "\n",
        "# 1. \n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "global_critic = Critic(state_dim)\n",
        "global_policy = Policy(state_dim,action_dim)\n",
        "global_critic.share_memory()\n",
        "global_policy.share_memory()\n",
        "\n",
        "global_opt_crt = SharedAdam(global_critic.parameters())\n",
        "global_opt_pol = SharedAdam(global_policy.parameters())\n",
        "\n",
        "\n",
        "global_ctr = mp.Value('i',0)\n",
        "lock = mp.Lock()\n",
        "\n",
        "pr = [mp.Process(target=test,args=(a,)) for _ in range(5)]\n",
        "\n",
        "for p in pr:\n",
        "    p.start()\n",
        "\n",
        "    \n",
        "for p in pr:\n",
        "    p.join()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9d61de8bab0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-9d61de8bab0b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    }
  ]
}